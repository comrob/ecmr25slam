- id: speaker-saska
  name: Martin Saska
  affiliation: Czech Technical University in Prague
  image: https://ieeexplore.ieee.org/mediastore/IEEE/content/freeimages/8860/10778592/10912745/saska-3547296-small.gif
  topic: "Long-term UAV deployment in challenging GNSS-denied conditions"
  online: false
  session: 2
  time: "11:00-11:40"
  order: 1
  bio: |
    Martin Saska received his Ph.D. degree at University of Wuerzburg, Germany, within PhD program of Elite Network of Bavaria. He founded and heads the Multi-robot Systems lab (<a href="http://mrs.felk.cvut.cz/" target="_blank" rel="noopener noreferrer">mrs.felk.cvut.cz</a>) at Czech Technical University in Prague with more than 40 researchers. He was a visiting scholar at University of Illinois at Urbana-Champaign and at University of Pennsylvania, USA. He is co-author of >200 publications in conferences and impacted journals, including IJRR, AURO, JFR, ASC, EJC, with >8200 citations indexed by Scholar and H-index 51. His team won multiple robotic challenges in MBZIRC 2017, MBZIRC 2020 and DARPA SubT competitions (<a href="http://mrs.felk.cvut.cz/projects/mbzirc" target="_blank" rel="noopener noreferrer">MBZIRC 2017</a>, <a href="http://mrs.felk.cvut.cz/mbzirc2020" target="_blank" rel="noopener noreferrer">MBZIRC 2020</a>, <a href="http://mrs.felk.cvut.cz/projects/darpa" target="_blank" rel="noopener noreferrer">DARPA SubT</a>).
  # presentation_link: "https://drive.google.com/file/d/example/view?usp=sharing"
  # video_link: "https://www.youtube.com/watch?v=dQw4w9WgXcQ"

- id: speaker-frosi
  name: Matteo Frosi
  affiliation: Politecnico di Milano
  image: https://airlab.deib.polimi.it/wp-content/uploads/2025/05/MatteoFrosi.png
  topic: "Beyond Vision: Radar-based SLAM for Robust Localization and Mapping"
  online: false
  session: 3
  time: "14:00-14:30"
  order: 2
  bio: |
    Matteo Frosi is a Research Assistant at the Artificial Intelligence and Robotics Laboratory (AIRLab) of Politecnico di Milano, where he also earned his Ph.D. His primary accomplishment lies in the development of versatile and robust Simultaneous Localization and Mapping (SLAM) systems for robots operating in challenging environments. A key achievement has been his success in bridging advanced theory with real-world application, successfully deploying his multi-sensor fusion frameworks (using LiDAR, camera, and radar) in industrial collaborations. These projects have solved critical problems in agricultural automation and autonomous inspection, enabling reliable navigation in unstructured terrain and ensuring long-term autonomy. Beyond this, Matteo actively contributes to the academic community by mentoring Master’s students and disseminating his research at major international conferences.

- id: speaker-dharmadhikari
  name: Mihir Dharmadhikari
  affiliation: Norwegian University of Science and Technology (NTNU)
  image: https://media.licdn.com/dms/image/v2/D4D03AQFvYNBWBYZeOg/profile-displayphoto-shrink_800_800/B4DZUQ2ig.HwAc-/0/1739744488368?e=1758758400&v=beta&t=XtqcQmLyfSZFG_jkmZR-KSh3ykaFKV-tEs28OEP6Ijo
  topic: "Resilient Multi-modal Perception"
  online: true
  session: 3
  time: "14:30-15:00"
  abstract: "The talk discusses methods for resilient localization and mapping - enabling autonomy functionalities - in GPS-denied and visually-degraded environments. Experiences from field deployments, including the winning run in the DARPA Subterranean Challenge are presented."
  order: 5
  qa:
    - question: "How do you handle multi-sensor calibration? Is it part of your state space or more of an external calibration?"
      answer: "We do not estimate the sensor extrinsics as part of the state space. We perform sensor extrinsic calibrations based on the modality. We use Kalibr for camera-IMU calibration. Similarly, we have explored various LiDAR-IMU and radar-IMU calibration techniques. As our sensors have rigid transformations between them and are placed close by, a transformation from CAD often can work fairly well, if nothing else as an initial guess."
    - question: "What about the time synchronization in the factor graph optimization? Do you consider discrete measurements or something else?"
      answer: "We indeed consider discrete measurements for our SLAM methods. Regarding time synchronization, we have developed a synchronization hardware and software system using a Teensy microcontroller that synchronizes the camera, LiDAR, radar, and IMU. Briefly speaking, the microcontroller provides triggering signals to the IMU, radar, and camera for synchronized sampling. Furthermore, the same microcontroller passes an NMEA message once per second to the LiDAR via UART, synchronizing the LiDAR timing the same way a GPS would. In the factor graph, the LiDAR point cloud is deskewed to the latest radar measurement timestamp. Through this synchronization system we achieve accurate time stamping of the measurements that are added to the factor graph.More details about the time synchronization system can be found here: https://arxiv.org/pdf/2507.05717"


- id: speaker-laconte
  name: Johann Laconte
  affiliation: French National Institute for Agriculture, Food, and Environment (INRAE)
  image: https://media.licdn.com/dms/image/v2/C4D03AQFt9_rXg6b_dQ/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1597151083827?e=1758758400&v=beta&t=4fRVqllLxSsaRiyW_LRDH_uu8opVHg28fbcAwqhdfTM
  topic: "Towards Robust and Resilient SLAM for Field Robotics"
  online: false
  session: 3
  time: "15:00-15:30"
  order: 3
  bio: |
    Johann Laconte's research focuses on mobile robotics and interactions with deformable, ever-changing environments. During his Ph.D., he participated in robotic deployments in unstructured environments like subarctic forests, work that earned him the second prize for the best French Ph.D. thesis in robotics. After postdoctoral research at Norlab and the University of Toronto (ASRL), he is now a Junior Research Chair at INRAE.

- id: speaker-artan
  name: Unal Artan
  affiliation: Örebro University
  image: https://media.licdn.com/dms/image/v2/D5603AQGjUHX9MRCTvA/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1720620910006?e=1758758400&v=beta&t=HFtPZEOZdiFCovy-gkNRqOZ3K__okTh_0cD7Qd-3ml0
  topic: "An Unsupervised Approach to Map Quality Assessment"
  online: true
  session: 1
  time: "09:10-09:40"
  abstract: "Maps are widely used in the robotics community for localization and path planning and the ability to identify incorrect or inaccurate regions of a map is an area of active research interest. For large environments, manual edits of the map can be very time consuming and a tool which can assist a map editor is needed. In this talk I will talk about the efforts we have taken to apply deep learning tools to create a tool that could be used to assist in evaluating the quality of a produced map (e.g., 2D occupancy grid map or 2D ndt map). The tool (autoencoder) uses only a given map as input to be independent of the underlying mapping algorithm. Where current methods for map quality assessment rely on ground-truth or labelled information for training classifiers, both of which can be difficult to obtain. Results from different environments will be providing highlighting the tools ability to identify regions with sparse data, clutter, and misregistrations. Possible future directions with the research will be shared."
  order: 6

- id: speaker-giammarino
  name: Luca Di Giammarino
  affiliation: Sapienza University of Rome
  image: https://media.licdn.com/dms/image/v2/D4E03AQGpPqYM_m7Blg/profile-displayphoto-shrink_200_200/B4EZWBYSjmHUAY-/0/1741632385313?e=1759968000&v=beta&t=_ydxxQ1JPebGcismKSVWWbvXn6GZxDswH5HCcIKiPxw
  topic: "Active Perception and Mapping: Learning to Localize in Space and Time"
  online: true
  session: 1
  time: "09:40-10:15"
  abstract: "This talk explores recent advances at the intersection of geometry, learning, and probabilistic modeling for robot localization and mapping. We present four complementary approaches that tackle key challenges in active perception: Gaussian splatting for real-time LiDAR odometry, continuous-time pose estimation via Gaussian belief propagation, and learning-based strategies for viewpoint selection in active localization. Together, these works push the boundaries of how autonomous systems perceive, move, and map the world, efficiently and intelligently, in both space and time."
  order: 4

